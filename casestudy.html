<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>Chronos: Case Study</title>
    <meta charset="utf-8" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link rel="stylesheet" href="css/casestudy.css">
    <link rel="shortcut icon" type="image/png" href="/favicon.png" />
    <script src="https://cdn.jsdelivr.net/npm/waypoints@4.0.1/lib/noframework.waypoints.min.js"></script>
    <script src="javascripts/csWaypoints.js"></script>
  </head>
  <body>
    <nav>
      <a href="index.html" class="hvr-bob"></a>
      <ul>
        <li><a href="casestudy.html" class="hvr-float-shadow">Case Study</a></li>
        <li><a href="bibliography.html" class="hvr-float-shadow">Bibliography</a></li>
        <li><a href="team.html" class="hvr-float-shadow">Team</a></li>
        <li><a href="https://github.com/chronos-project" class="hvr-float-shadow"><img src="images/icons/chronos_github_gray.png" alt="Github logo" /></a></li>
      </ul>
    </nav>
    <main>
      <nav id="toc">
        <ul>
          <li class="h2 active" id="introduction-toc" data-element="introduction">Introduction</li>
          <li class="h2" id="what-is-event-data-toc" data-element="what-is-event-data-">What is Event Data?
            <ul>
              <li class="h3" data-element="event-data-vs-entity-data">Event Data vs Entity Data</li>
              <li class="h3" data-element="streams-and-tables">Streams and Tables</li>
            </ul>
          </li>
          <li class="h2" id="existing-solutions-toc" data-element="existing-solutions">Existing Solutions
            <ul>
              <li class="h3" data-element="yandex-metrica">Yandex Metrica</li>
              <li class="h3" data-element="eventhub">EventHub</li>
              <li class="h3" data-element="countly-community-edition">Countly Community Edition</li>
              <li class="h3" data-element="chronos">Chronos</li>
            </ul>
          </li>
        </ul>
      </nav>
      <article>
        <div id='markdown'>
          <h1 id="case-study">Case Study</h1>
          <h2 id="introduction">Introduction</h2>
          <p>Chronos is an event-capturing framework for greenfield applications, and is built using NodeJS, Apache Kafka, TimescaleDB, and PipelineDB. It allows developers to easily capture and store user events that happen on the client side, and then perform data exploration on the captured events in order to aid business logic. By using Apache Kafka, Chronos is a streaming system at its core and is thus easily expandable to the developer's needs. Further, Chronos is deployed using Docker and comes with a CLI that abstracts the difficulties in installing and running the system.</p>
          <p>When building Chronos we faced several difficulties. The first were the various challenges in sending event data to the API server including limited browser resources, security concerns, and payload size limitations. Second was the issue of code coupling, or making sure that Chronos could easily be expanded to fit a developers needs. Third, we had to overcome the difficulties with abstracting away any difficulties for the developer when working with Apache Kafka, including installation, configuration, and potential errors. Lastly, we had to overcome the difficulties in storing event data while still making data exploration possible for a large range of developers.</p>
          <p>This case study will begin by describing what event data is and how it contrasts from entity data. Next, we will define what a greenfield application is and review some of the existing solutions for this area and what some problems there are in using these systems. Lastly, we will describe how we went about building Chronos in order to solve these problems and how we overcame the challenges that presented themselves along the way.</p>
          <h2 id="what-is-event-data-">What is Event Data?</h2>
          <h3 id="event-data-vs-entity-data">Event Data vs Entity Data</h3>
          <p>Very often, when we speak of "data" in an application we generally tend to think of data that resides in a database that is modeled after real world entities. This may be a shopping cart, a bank account, a character in an online video game, etc. In each of these cases, we are dealing with **entity data**, or data that describes the current state of some entity. This type of data is generally what comes to mind when we think of SQL and Relational Databases.</p>
          <table>
            <thead>
              <tr>
                <th>Column Name</th>
                <th>Value</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>id</td>
                <td>327</td>
              </tr>
              <tr>
                <td>account_name</td>
                <td>Bugman27</td>
              </tr>
              <tr>
                <td>email</td>
                <td>imabug@foo.bar</td>
              </tr>
              <tr>
                <td>account_status</td>
                <td>active</td>
              </tr>
              <tr>
                <td>name</td>
                <td>Franz Kafka</td>
              </tr>
              <tr>
                <td>age</td>
                <td>53</td>
              </tr>
            </tbody>
          </table>
          <p class="caption">Typical example of entity data</p>
          <p>However, there is an emerging realization that while we genreally tend to think of applications as tracking entity data, there is also a constantly occuring stream of events. An <strong>event</strong> in this case is any action that occurs in an application. Examples could be a user clicking on a link, submitting a payment, creating a character, landing on a page, etc.</p>
          <pre>
            <code class="language-json">
{
  <span class="json-key">"eventType"</span>: <span class="json-value-string">"pageview"</span>,
  <span class="json-key">"timestamp"</span>: <span class="json-value-string">"2018 20:29:48 GMT-0600"</span>,
  <span class="json-key">"page URL"</span>: <span class="json-value-string">"www.example.com"</span>,
  <span class="json-key">"pageTitle"</span>: <span class="json-value-string">"Example Title"</span>,
  <span class="json-key">"user"</span>: {
    <span class="json-key">"userId"</span>: <span class="json-value-number">7689476946</span>,
     <span class="json-key">"userCountry"</span>: <span class="json-value-string">"USA"</span>,
     <span class="json-key">"userLanguage"</span>: <span class="json-value-string">"en-us"</span>,
     <span class="json-key">"userAgent"</span>: <span class="json-value-string">"Chrome"</span>,
     ...
}
            </code>
          </pre>
          <p class="caption">Example of a <code>pageview</code> event as a JSON object</p>
          <p>As such, <strong>event data</strong> is data that models each of these events. Unlike entity data which is core to the business logic of an application, event data is a kind of metadata, or data about data, which describes how an application is being used, and is usually not central to its business logic. In this case, if entity data is a noun which carries around state, then event data is a verb which describes an action.</p>
          <p>Since event data describes how an application is being used, capturing and analyzing this data provides a major competitive advantage since it can be used to positively iterate on a product and increase profits.[1] However, if a developer wants to track event data, then unlike entity data, all the events would have to be stored since it is with the total set of events that one can analyze the data and draw conclusions. In other words, events are treated as immutable and are never updated and rarely deleted. The following table maps out the differences in this model between event and entity data thus far:[2]</p>
          <table>
            <thead>
              <tr>
                <th>Entity Data</th>
                <th>Event Data</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Strict schema</td>
                <td>Felxible schema</td>
              </tr>
              <tr>
                <td>Normalized</td>
                <td>Denormalized</td>
              </tr>
              <tr>
                <td>Shorter</td>
                <td>Wider</td>
              </tr>
              <tr>
                <td>Describes nouns</td>
                <td>Describes verbs</td>
              </tr>
              <tr>
                <td>Describes now</td>
                <td>Describes trends over time</td>
              </tr>
              <tr>
                <td>Updates</td>
                <td>Appends</td>
              </tr>
              <tr>
                <td>O(N)</td>
                <td>O(N * K)</td>
              </tr>
            </tbody>
          </table>
          <p>While this is a good first attempt to model events, the key problem with ending here is that while there is definitely a legitimate distinction between event data and entity data, the two cannot be completely partitioned into unrelated categories. To understand why this is, we need to discuss the &quot;theory of streams and tables&quot; as concevied of by figures such as Martin Kleppmann, Jay Kreps, and Tyler Akidau.</p>
          <h3 id="streams-and-tables">Streams and Tables</h3>
          <p>To start with, we&#39;ll need some working definitions of what streams and tables are. To borrow from Akidau, a <strong>stream</strong> is &quot;[a]n element-by-element view of the evolution of a dataset over time.&quot;[3] Streams have traditionally been processed by streaming systems that are designed to handle unbounded (infinite) datasets. A <strong>table</strong> is &quot;[a] holistic view of a dataset at a specific point in time&quot;[2] and is traditionally handled within relational databases (i.e. SQL). We can expand these definitions by saying that streams are data that are in motion, while tables are data that are at rest.</p>
          <p>Staying with tables for a moment, it&#39;s worth remembering that the underlying data structure for many databases is a log, more specifically one that is append-only. As each transaction takes place for a particular entity, they are recorded to the log. The log, then, can be seen as a kind of stream of data which can be used to re-create the state of a table within our database. More broadly speaking, the aggregation of a stream will give us a table.</p>
          <p>(diagram)</p>
          <p>The inverse of this relationship is that streams are created from tables as a kind of change-log for the table. In other words, if we look at the changes that occur on a particular entity over time, we end up with a stream of data.</p>
          <p>(diagram)</p>
          <p>To bring this back to event data and entity data: if we were to write all the event data within our application onto a log, then we would be able to re-create the state of any entity data that we needed. In other words, rather than being two separate kinds of data, event data are the individual data points that make up the stream of our application, while entity data are the aggregated snapshots of our stream of event data.</p>
          <p>In this respect, though databases are often thought of as the &quot;source of truth&quot; in an application, they actually contain just a set of aggregations of event data at a particular point in time. It is the log that holds the event data that is the actual source of truth of our application since it contains the fundamental building blocks to recreate the state of the application.</p>
          <p>(image)</p>
          <p>Given all this, it should be clear that there are several good reasons for capturing event data:</p>
          <ol>
            <li>Event data provide rich information that can be used to see how users are using your application</li>
            <li>Event data can validate business logic or be used to form new strategies</li>
            <li>Event data are the fundamental building blocks of the state of an application</li>
          </ol>
          <p>The main difficulty in capturing and using event data is that since for so long they&#39;ve been seen to exist implicitly in an application they don&#39;t have a proper place within the architecture of many set ups. Further, since events are constantly happening in real time, any system for capturing and storing event data needs to be able to map to this stream of events and store data in an apropos way.</p>
          <p>Thankfully, streaming architectures for web applications have been developing at a quick pace over the last decade and a half since the release of MapReduce in 2003. However, they are a specialized field and have a significant learning curve to use, let alone to then go and implement them for production. It would be unrealistic for ever developer to learn how to implement such a system for capturing event data, especially for greenfield applications when the developer isn&#39;t even sure how the application will be used yet.</p>
          <h2 id="existing-solutions">Existing Solutions</h2>
          <p>Luckily, there are already existing solutions for a developer who wishes to capture, store, and analyze event data. However, many of these solutions are proprietary in nature and while they could be used for greenfield applications, they are better suited for larger or enterprise level applications. With these solutions we generally found the following problems:</p>
          <ol>
            <li>Monetary costs</li>
            <li>Data lives on the proprietary service&#39;s servers</li>
            <li>Data may be sampled</li>
            <li>You may not have access to your raw data</li>
            <li>Manual implementation of events to capture</li>
          </ol>
          <p>The justifications of these drawbacks should be straightforward:</p>
          <ol>
            <li>Since greenfield applications are usually in a prototype or new phase, they likely don&#39;t have or want to spend a lot of money on proprietary solutions</li>
            <li>With the growing concern about how people&#39;s data is being used, it&#39;s always a gamble to have your data hosted on a service&#39;s server that you don&#39;t have direct access to</li>
            <li>Same problem as #2</li>
            <li>If you can only access data through an API and can never get at the raw data itself, not only does that limit what you can do with the data, but it makes it hard if not impossible to transfer it to another solution</li>
            <li>Since a greenfield application doesn&#39;t yet know what events to capture, requiring manual implementation of event capturing is counter-intuitive</li>
          </ol>
          <p>Of the various solutions, there were three that we found in particular better suited our use case: Yandex Metrica, Event Hub, and Countly Community Edition.</p>
          <h3 id="yandex-metrica">Yandex Metrica</h3>
          <p>One existing solution is provided by <a href="https://metrica.yandex.com/about?">Yandex Metrica</a>, which is a product of the larger <a href="https://yandex.com/">Yandex</a> company. Two of the standout advantages of Yandex Metrica is that they provide the ability to create &quot;click maps&quot;, visual representations on a web page where a user clicked through, as well as heat maps that show which sections of your pages have the most activity. Yandex also has no fee associated with it.</p>
          <p>While Yandex does require your data to live on their servers, they are required to respect European data privacy laws and also encrypt your data so it can&#39;t be used by other analytical services. Further, any data they look at for their own analytical purposes is done so in a way that your data remains anonymous.</p>
          <p>One big drawback is that Yandex requires most event capturing to be manually implemented. Another problem is that while you do have access to your raw data, you can only access via their API, and so you have to extract and store your data manually.</p>
          <h3 id="eventhub">EventHub</h3>
          <p>Another solution for Greenfield applications is <a href="https://github.com/Codecademy/EventHub">EventHub</a>, which is an open source event tracking/storage system written in Java. It has some impressive analytical capabilities such as cohort and funneling queries, but it has little-to-no automatic tracking of events.</p>
          <p>Two other drawbacks of EventHub are that it&#39;s timestamp is processing time only (i.e. it logs the timestamp when the data hits the server as opposed to when it occurs in the client). This is mitigated by the fact that any event capturing a developer implements can just include a client-side timestamp. However, the largest issue is that the project has been abandoned for 5 years now, so support would likely be totally absent.</p>
          <h3 id="countly-community-edition">Countly Community Edition</h3>
          <p>Of the three choices, <a href="https://github.com/Countly/countly-server">Countly&#39;s community edition</a> (open source) was the strongest option. Countly allows not only for a quick manual setup on your own server, but also provides a one-click setup option for hosting your server on Digital Ocean. Their tracker is a JavaScrpit SDK that tracks the following events automatically:</p>
          <ul>
            <li>sessions</li>
            <li>pageviews (both for tradition websites and single page applications)</li>
            <li>link clicks (both on a link or those on a parent node)</li>
            <li>form submissions</li>
          </ul>
          <p>Two other events, mouse clicks and mouse scrolls, are only automatically captured in the enterprise edition. Since Countly must be ran on a server you own, you have access to all of your own data (which is stored in MongoDB), and they also provide a UI for visualizing and exploring your data.</p>
          <p>The largest drawbacks to Countly are the limited number of events captured (anything else must be implemented manually) and that their pipeline setup is a direct connection from their API to their database (this is also true of EventHub). Why this latter design is problematic will be discussed below.</p>
          <h3 id="chronos">Chronos</h3>
          <p>For Chronos to be an alternative in this space, it must solve the problems listed above as well as provide some benefits compared to the existing solutions. In the end, Chronos was able solve the 5 problems above:</p>
          <ol>
            <li>Chronos is open source, and thus free to use</li>
            <li>Data only exists on the server you host Chronos on and so you don&#39;t have to fear its security</li>
            <li>Chronos will never sample your data since it&#39;s just an infrastructure</li>
            <li>Chronos provides access to your raw data</li>
            <li>Chronos provides a config file that specifies which events you&#39;d like to capture: everything else is automated</li>
          </ol>
          <p>In addition to this, we provided a way for Chronos to visualize any queries over the data. We also wanted to make sure that Chronos would be space efficient since a greenfield application shouldn&#39;t be spending lots of money on their own server to collect data. Below we detail how we went about building Chronos and the challenges we faced.</p>
        </div>
      </article>
    </main>
    <footer>
      <p>Current Version: 0.9.0</p>
      <p><a href="casestudy.html" class="hvr-float-shadow">Case Study</a> | <a href="bibliography.html" class="hvr-float-shadow">Bibliography</a> | <a href="team.html" class="hvr-float-shadow">Team</a></p>
    </footer>
  </body>
</html>
